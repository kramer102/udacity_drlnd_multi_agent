{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tennis Agents\n",
    "---\n",
    "\n",
    "In this notebook, we train the Unity ML-Agent to solve two agents playing tennis\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ddpg_agent_tennis import Agent\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "# one arm\n",
    "# env = UnityEnvironment(file_name=one_arm_file, seed=seed)\n",
    "\n",
    "# many arms\n",
    "env = UnityEnvironment(file_name=\"/home/robert/RL_ubuntu/udacity_drlnd_multi_agent/Tennis_Linux/Tennis.x86_64\")\n",
    "# no_graphics=True\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "\n",
    "# examine the state space\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "\n",
    "# Set seed\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with DDPG\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  Alternatively, you can skip to the next code cell to load the pre-trained weights from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 200\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 300\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 400\tAverage Score: 0.01\tScore: 0.00\n",
      "Episode 500\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 600\tAverage Score: 0.02\tScore: 0.10\n",
      "Episode 700\tAverage Score: 0.07\tScore: 0.10\n",
      "Episode 800\tAverage Score: 0.09\tScore: 0.00\n",
      "Episode 900\tAverage Score: 0.15\tScore: 0.09\n",
      "Episode 1000\tAverage Score: 0.25\tScore: 0.10\n",
      "Episode 1045\tAverage Score: 0.51\tScore: 2.70\n",
      "Environment solved in 945 episodes!\tAverage Score: 0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ddpg(n_episodes=3000, max_t=10000, from_checkpoint=False):\n",
    "    if from_checkpoint:\n",
    "        agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "        agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_g = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]     # reset the environment    \n",
    "        states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "        agent.reset()\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states, add_noise=True)\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            states = next_states\n",
    "            scores+= env_info.rewards\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        score = np.max(scores)\n",
    "        scores_deque.append(score)\n",
    "        scores_g.append(score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))   \n",
    "        if np.mean(scores_deque) > 0.5:\n",
    "            torch.save(agent.actor_local.state_dict(), 'final_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'final_critic.pth')\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            break\n",
    "    return scores_g\n",
    "\n",
    "scores = ddpg()\n",
    "#scores = ddpg(from_checkpoint=True)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (bn0): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=24, out_features=400, bias=True)\n",
      "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=300, out_features=2, bias=True)\n",
      ")\n",
      "Critic(\n",
      "  (fcs1): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=258, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(agent.actor_local)\n",
    "print(agent.critic_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!\n",
    "\n",
    "Reload env if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 2.600000038743019\n",
      "Score (max over agents) from episode 2: 2.7000000402331352\n",
      "Score (max over agents) from episode 3: 2.600000038743019\n",
      "Score (max over agents) from episode 4: 2.7000000402331352\n",
      "Score (max over agents) from episode 5: 2.600000038743019\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "\n",
    "agent.actor_local.load_state_dict(torch.load('final_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('final_critic.pth'))\n",
    "\n",
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = agent.act(states, add_noise=False)       # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "301.4px",
    "left": "632.4px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
